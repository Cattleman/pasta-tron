{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==0.9.0\r\n",
      "asn1crypto==0.24.0\r\n",
      "astor==0.8.1\r\n",
      "attrs==19.3.0\r\n",
      "backcall==0.1.0\r\n",
      "bleach==3.1.0\r\n",
      "cachetools==4.0.0\r\n",
      "certifi==2019.11.28\r\n",
      "chardet==3.0.4\r\n",
      "cryptography==2.1.4\r\n",
      "cycler==0.10.0\r\n",
      "decorator==4.4.1\r\n",
      "defusedxml==0.6.0\r\n",
      "entrypoints==0.3\r\n",
      "enum34==1.1.6\r\n",
      "gast==0.2.2\r\n",
      "google-auth==1.10.0\r\n",
      "google-auth-oauthlib==0.4.1\r\n",
      "google-pasta==0.1.8\r\n",
      "grpcio==1.26.0\r\n",
      "h5py==2.10.0\r\n",
      "idna==2.6\r\n",
      "importlib-metadata==1.4.0\r\n",
      "ipykernel==5.1.3\r\n",
      "ipython==7.11.1\r\n",
      "ipython-genutils==0.2.0\r\n",
      "ipywidgets==7.5.1\r\n",
      "jedi==0.15.2\r\n",
      "Jinja2==2.10.3\r\n",
      "jsonschema==3.2.0\r\n",
      "jupyter==1.0.0\r\n",
      "jupyter-client==5.3.4\r\n",
      "jupyter-console==6.0.0\r\n",
      "jupyter-core==4.6.1\r\n",
      "jupyter-http-over-ws==0.0.7\r\n",
      "Keras-Applications==1.0.8\r\n",
      "Keras-Preprocessing==1.1.0\r\n",
      "keyring==10.6.0\r\n",
      "keyrings.alt==3.0\r\n",
      "kiwisolver==1.1.0\r\n",
      "Markdown==3.1.1\r\n",
      "MarkupSafe==1.1.1\r\n",
      "matplotlib==3.1.2\r\n",
      "mistune==0.8.4\r\n",
      "more-itertools==8.0.2\r\n",
      "nbconvert==5.6.1\r\n",
      "nbformat==5.0.3\r\n",
      "notebook==6.0.2\r\n",
      "numpy==1.18.1\r\n",
      "oauthlib==3.1.0\r\n",
      "opt-einsum==3.1.0\r\n",
      "pandocfilters==1.4.2\r\n",
      "parso==0.5.2\r\n",
      "pexpect==4.7.0\r\n",
      "pickleshare==0.7.5\r\n",
      "prometheus-client==0.7.1\r\n",
      "prompt-toolkit==2.0.10\r\n",
      "protobuf==3.11.2\r\n",
      "ptyprocess==0.6.0\r\n",
      "pyasn1==0.4.8\r\n",
      "pyasn1-modules==0.2.8\r\n",
      "pycrypto==2.6.1\r\n",
      "Pygments==2.5.2\r\n",
      "pygobject==3.26.1\r\n",
      "pyparsing==2.4.6\r\n",
      "pyrsistent==0.15.7\r\n",
      "python-dateutil==2.8.1\r\n",
      "pyxdg==0.25\r\n",
      "pyzmq==18.1.1\r\n",
      "qtconsole==4.6.0\r\n",
      "requests==2.22.0\r\n",
      "requests-oauthlib==1.3.0\r\n",
      "rsa==4.0\r\n",
      "scipy==1.4.1\r\n",
      "SecretStorage==2.3.1\r\n",
      "Send2Trash==1.5.0\r\n",
      "six==1.13.0\r\n",
      "tensorboard==2.1.0\r\n",
      "tensorflow==2.1.0\r\n",
      "tensorflow-estimator==2.1.0\r\n",
      "termcolor==1.1.0\r\n",
      "terminado==0.8.3\r\n",
      "testpath==0.4.4\r\n",
      "tornado==6.0.3\r\n",
      "traitlets==4.3.3\r\n",
      "urllib3==1.25.7\r\n",
      "wcwidth==0.1.8\r\n",
      "webencodings==0.5.1\r\n",
      "Werkzeug==0.16.0\r\n",
      "widgetsnbextension==3.5.1\r\n",
      "wrapt==1.11.2\r\n",
      "zipp==0.6.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/5e/23dcc0ce3cc2abe92efd3cd61d764bee6ccdf1b667a1fb566f45dc249953/Pillow-7.0.0-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 1.5MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pillow\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/usr/local/lib/python3.6/dist-packages/PIL'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from PIL import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def crop(path, origional_image, height, width, k, page, area):\n",
    "    im = Image.open(input)\n",
    "    imgwidth, imgheight = im.size\n",
    "    for i in range(0,imgheight,height):\n",
    "        for j in range(0,imgwidth,width):\n",
    "            box = (j, i, j+width, i+height)\n",
    "            a = im.crop(box)\n",
    "            try:\n",
    "                o = a.crop(area)\n",
    "                o.save(os.path.join(path,\"PNG\",\"%s\" % page,\"IMG-%s.png\" % k))\n",
    "            except:\n",
    "                pass\n",
    "            k +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/project/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/project/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting image_slicer\n",
      "  Downloading https://files.pythonhosted.org/packages/d6/1e/6afd4b8c88f888fb7b909b02c102709c413d0dd1ed9047914002b87bc6b9/image_slicer-0.3.0-py3-none-any.whl\n",
      "Requirement already satisfied: Pillow>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from image_slicer) (7.0.0)\n",
      "Installing collected packages: image-slicer\n",
      "Successfully installed image-slicer-0.3.0\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install image_slicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('/project/data/raw/farfalle/IMG_20200308_170810.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4032, 3024)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = im.resize((400, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "tile cannot extend outside image",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \"\"\"\n\u001b[1;32m    642\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PNG\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2102\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2103\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m             \u001b[0;31m# do what we can to clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"eXIf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexif\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m     \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"IEND\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                 \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpushes_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetfd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: tile cannot extend outside image"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=0x0 at 0x7F0329318CC0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 % 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_20200308_170810-Copy1.jpg  IMG_20200308_170810_06_06.png\r\n",
      "IMG_20200308_170810.jpg        IMG_20200308_170810_06_07.png\r\n",
      "IMG_20200308_170810_01_01.png  IMG_20200308_170810_06_08.png\r\n",
      "IMG_20200308_170810_01_02.png  IMG_20200308_170810_06_09.png\r\n",
      "IMG_20200308_170810_01_03.png  IMG_20200308_170810_06_10.png\r\n",
      "IMG_20200308_170810_01_04.png  IMG_20200308_170810_07_01.png\r\n",
      "IMG_20200308_170810_01_05.png  IMG_20200308_170810_07_02.png\r\n",
      "IMG_20200308_170810_01_06.png  IMG_20200308_170810_07_03.png\r\n",
      "IMG_20200308_170810_01_07.png  IMG_20200308_170810_07_04.png\r\n",
      "IMG_20200308_170810_01_08.png  IMG_20200308_170810_07_05.png\r\n",
      "IMG_20200308_170810_01_09.png  IMG_20200308_170810_07_06.png\r\n",
      "IMG_20200308_170810_01_10.png  IMG_20200308_170810_07_07.png\r\n",
      "IMG_20200308_170810_02_01.png  IMG_20200308_170810_07_08.png\r\n",
      "IMG_20200308_170810_02_02.png  IMG_20200308_170810_07_09.png\r\n",
      "IMG_20200308_170810_02_03.png  IMG_20200308_170810_07_10.png\r\n",
      "IMG_20200308_170810_02_04.png  IMG_20200308_170810_08_01.png\r\n",
      "IMG_20200308_170810_02_05.png  IMG_20200308_170810_08_02.png\r\n",
      "IMG_20200308_170810_02_06.png  IMG_20200308_170810_08_03.png\r\n",
      "IMG_20200308_170810_02_07.png  IMG_20200308_170810_08_04.png\r\n",
      "IMG_20200308_170810_02_08.png  IMG_20200308_170810_08_05.png\r\n",
      "IMG_20200308_170810_02_09.png  IMG_20200308_170810_08_06.png\r\n",
      "IMG_20200308_170810_02_10.png  IMG_20200308_170810_08_07.png\r\n",
      "IMG_20200308_170810_03_01.png  IMG_20200308_170810_08_08.png\r\n",
      "IMG_20200308_170810_03_02.png  IMG_20200308_170810_08_09.png\r\n",
      "IMG_20200308_170810_03_03.png  IMG_20200308_170810_08_10.png\r\n",
      "IMG_20200308_170810_03_04.png  IMG_20200308_170810_09_01.png\r\n",
      "IMG_20200308_170810_03_05.png  IMG_20200308_170810_09_02.png\r\n",
      "IMG_20200308_170810_03_06.png  IMG_20200308_170810_09_03.png\r\n",
      "IMG_20200308_170810_03_07.png  IMG_20200308_170810_09_04.png\r\n",
      "IMG_20200308_170810_03_08.png  IMG_20200308_170810_09_05.png\r\n",
      "IMG_20200308_170810_03_09.png  IMG_20200308_170810_09_06.png\r\n",
      "IMG_20200308_170810_03_10.png  IMG_20200308_170810_09_07.png\r\n",
      "IMG_20200308_170810_04_01.png  IMG_20200308_170810_09_08.png\r\n",
      "IMG_20200308_170810_04_02.png  IMG_20200308_170810_09_09.png\r\n",
      "IMG_20200308_170810_04_03.png  IMG_20200308_170810_09_10.png\r\n",
      "IMG_20200308_170810_04_04.png  IMG_20200308_170810_10_01.png\r\n",
      "IMG_20200308_170810_04_05.png  IMG_20200308_170810_10_02.png\r\n",
      "IMG_20200308_170810_04_06.png  IMG_20200308_170810_10_03.png\r\n",
      "IMG_20200308_170810_04_07.png  IMG_20200308_170810_10_04.png\r\n",
      "IMG_20200308_170810_04_08.png  IMG_20200308_170810_10_05.png\r\n",
      "IMG_20200308_170810_04_09.png  IMG_20200308_170810_10_06.png\r\n",
      "IMG_20200308_170810_04_10.png  IMG_20200308_170810_10_07.png\r\n",
      "IMG_20200308_170810_05_01.png  IMG_20200308_170810_10_08.png\r\n",
      "IMG_20200308_170810_05_02.png  IMG_20200308_170810_10_09.png\r\n",
      "IMG_20200308_170810_05_03.png  IMG_20200308_170810_10_10.png\r\n",
      "IMG_20200308_170810_05_04.png  IMG_20200308_170811.jpg\r\n",
      "IMG_20200308_170810_05_05.png  IMG_20200308_170819.jpg\r\n",
      "IMG_20200308_170810_05_06.png  IMG_20200308_170823.jpg\r\n",
      "IMG_20200308_170810_05_07.png  IMG_20200308_170824.jpg\r\n",
      "IMG_20200308_170810_05_08.png  IMG_20200308_170826.jpg\r\n",
      "IMG_20200308_170810_05_09.png  IMG_20200308_170830.jpg\r\n",
      "IMG_20200308_170810_05_10.png  IMG_20200308_170833.jpg\r\n",
      "IMG_20200308_170810_06_01.png  IMG_20200308_171359.jpg\r\n",
      "IMG_20200308_170810_06_02.png  IMG_20200308_171401.jpg\r\n",
      "IMG_20200308_170810_06_03.png  IMG_20200308_171404.jpg\r\n",
      "IMG_20200308_170810_06_04.png  IMG_20200308_171406.jpg\r\n",
      "IMG_20200308_170810_06_05.png\r\n"
     ]
    }
   ],
   "source": [
    "!ls /project/data/raw/farfalle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `iage_slicer` not found.\n"
     ]
    }
   ],
   "source": [
    "image_slicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_farfalle_list = [\n",
    "\"IMG_20200308_170810.jpg\",\n",
    "\"IMG_20200308_170811.jpg\",\n",
    "\"IMG_20200308_170819.jpg\",\n",
    "\"IMG_20200308_170823.jpg\",\n",
    "\"IMG_20200308_170824.jpg\",\n",
    "\"IMG_20200308_170826.jpg\",\n",
    "\"IMG_20200308_170830.jpg\",\n",
    "\"IMG_20200308_170833.jpg\",\n",
    "\"IMG_20200308_171359.jpg\",\n",
    "\"IMG_20200308_171401.jpg\",\n",
    "\"IMG_20200308_171404.jpg\",\n",
    "\"IMG_20200308_171406.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> tiles = image_slicer.slice('cake.jpg', 4, save=False)\n",
    "# >>> image_slicer.save_tiles(tiles, directory='~/cake_slices',\\\n",
    "#                             prefix='slice', format='jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170810\n",
      "170811\n",
      "170819\n",
      "170823\n",
      "170824\n",
      "170826\n",
      "170830\n",
      "170833\n",
      "171359\n",
      "171401\n",
      "171404\n",
      "171406\n"
     ]
    }
   ],
   "source": [
    "for im in raw_farfalle_list:\n",
    "    print(im[-10:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image-170810 Done!\n",
      "Image-170811 Done!\n",
      "Image-170819 Done!\n",
      "Image-170823 Done!\n",
      "Image-170824 Done!\n",
      "Image-170826 Done!\n",
      "Image-170830 Done!\n",
      "Image-170833 Done!\n",
      "Image-171359 Done!\n",
      "Image-171401 Done!\n",
      "Image-171404 Done!\n",
      "Image-171406 Done!\n"
     ]
    }
   ],
   "source": [
    "for im in raw_farfalle_list:\n",
    "    slice_raw_images(raw_image=im, base_path=\"/project/data/raw/farfalle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_20200308_172029.jpg  IMG_20200308_172039.jpg  IMG_20200308_172123.jpg\r\n",
      "IMG_20200308_172031.jpg  IMG_20200308_172042.jpg  IMG_20200308_172128.jpg\r\n",
      "IMG_20200308_172037.jpg  IMG_20200308_172109.jpg  IMG_20200308_172131.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!ls /project/data/raw/orzo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_orzo_list = [\n",
    "    \"IMG_20200308_172029.jpg\",\n",
    "    \"IMG_20200308_172039.jpg\", \n",
    "    \"IMG_20200308_172123.jpg\",\n",
    "    \"IMG_20200308_172031.jpg\",\n",
    "    \"IMG_20200308_172042.jpg\",\n",
    "    \"IMG_20200308_172128.jpg\",\n",
    "    \"IMG_20200308_172037.jpg\",\n",
    "    \"IMG_20200308_172109.jpg\",\n",
    "    \"IMG_20200308_172131.jpg\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_20200308_165622.jpg  IMG_20200308_165708.jpg  IMG_20200308_170020.jpg\r\n",
      "IMG_20200308_165629.jpg  IMG_20200308_165717.jpg  IMG_20200308_170023.jpg\r\n",
      "IMG_20200308_165631.jpg  IMG_20200308_170007.jpg  IMG_20200308_170030.jpg\r\n",
      "IMG_20200308_165635.jpg  IMG_20200308_170009.jpg  IMG_20200308_170033.jpg\r\n",
      "IMG_20200308_165656.jpg  IMG_20200308_170010.jpg  IMG_20200308_170037.jpg\r\n",
      "IMG_20200308_165701.jpg  IMG_20200308_170015.jpg  IMG_20200308_170053.jpg\r\n",
      "IMG_20200308_165705.jpg  IMG_20200308_170018.jpg  IMG_20200308_170055.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!ls /project/data/raw/penne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_penne_list = [\n",
    "    \"IMG_20200308_165622.jpg\", \n",
    "    \"IMG_20200308_165708.jpg\",\n",
    "    \"IMG_20200308_170020.jpg\",\n",
    "    \"IMG_20200308_165629.jpg\",\n",
    "    \"IMG_20200308_170023.jpg\",\n",
    "    \"IMG_20200308_165631.jpg\",\n",
    "    \"IMG_20200308_170007.jpg\",\n",
    "    \"IMG_20200308_170030.jpg\",\n",
    "    \"IMG_20200308_165635.jpg\",\n",
    "    \"IMG_20200308_170009.jpg\",\n",
    "    \"IMG_20200308_170033.jpg\",\n",
    "    \"IMG_20200308_165656.jpg\",\n",
    "    \"IMG_20200308_170010.jpg\",\n",
    "    \"IMG_20200308_170037.jpg\",\n",
    "    \"IMG_20200308_165701.jpg\",\n",
    "    \"IMG_20200308_170015.jpg\",\n",
    "    \"IMG_20200308_170053.jpg\",\n",
    "    \"IMG_20200308_165705.jpg\",\n",
    "    \"IMG_20200308_170018.jpg\",\n",
    "    \"IMG_20200308_170055.jpg\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_raw_images(raw_image:str, base_path:str, label:str, num_slices:int = 100) -> None:\n",
    "    \n",
    "    # num_slice must be even\n",
    "    assert num_slices % 2 == 0 \n",
    "    \n",
    "\n",
    "    tiles = image_slicer.slice(f\"{base_path}/{raw_image}\", num_slices, save=False)\n",
    "    image_slicer.save_tiles(tiles,\n",
    "                            directory=f\"{base_path}/sliced_images\",\n",
    "                            prefix=f'{label}_{raw_image[-10:-4]}_slice')# , format='jpg')\n",
    "    \n",
    "    \n",
    "    print(f\"Image-{raw_image[-10:-4]} Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image-172029 Done!\n",
      "Image-172039 Done!\n",
      "Image-172123 Done!\n",
      "Image-172031 Done!\n",
      "Image-172042 Done!\n",
      "Image-172128 Done!\n",
      "Image-172037 Done!\n",
      "Image-172109 Done!\n",
      "Image-172131 Done!\n"
     ]
    }
   ],
   "source": [
    "for orzo in raw_orzo_list:\n",
    "    slice_raw_images(raw_image=orzo, \n",
    "                     base_path=\"/project/data/raw/orzo\", \n",
    "                     label=\"orzo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image-165622 Done!\n",
      "Image-165708 Done!\n",
      "Image-170020 Done!\n",
      "Image-165629 Done!\n",
      "Image-170023 Done!\n",
      "Image-165631 Done!\n",
      "Image-170007 Done!\n",
      "Image-170030 Done!\n",
      "Image-165635 Done!\n",
      "Image-170009 Done!\n",
      "Image-170033 Done!\n",
      "Image-165656 Done!\n",
      "Image-170010 Done!\n",
      "Image-170037 Done!\n",
      "Image-165701 Done!\n",
      "Image-170015 Done!\n",
      "Image-170053 Done!\n",
      "Image-165705 Done!\n",
      "Image-170018 Done!\n",
      "Image-170055 Done!\n"
     ]
    }
   ],
   "source": [
    "for penne in raw_penne_list:\n",
    "    slice_raw_images(raw_image=penne, \n",
    "                     base_path=\"/project/data/raw/penne\", \n",
    "                     label=\"penne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Left off here - working on getting the slices to get saved out in different directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_slicer.save_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "slice_raw_images(raw_image_list=raw_farfalle_list, base_path=\"/project/data/raw/farfalle\", num_slices=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop(path=\"/project/data/clipped/farfalle\", )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_slicer.slice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Tile #1 - IMG_20200308_170810_01_01.png>,\n",
       " <Tile #2 - IMG_20200308_170810_01_02.png>,\n",
       " <Tile #3 - IMG_20200308_170810_01_03.png>,\n",
       " <Tile #4 - IMG_20200308_170810_01_04.png>,\n",
       " <Tile #5 - IMG_20200308_170810_01_05.png>,\n",
       " <Tile #6 - IMG_20200308_170810_01_06.png>,\n",
       " <Tile #7 - IMG_20200308_170810_01_07.png>,\n",
       " <Tile #8 - IMG_20200308_170810_01_08.png>,\n",
       " <Tile #9 - IMG_20200308_170810_01_09.png>,\n",
       " <Tile #10 - IMG_20200308_170810_01_10.png>,\n",
       " <Tile #11 - IMG_20200308_170810_02_01.png>,\n",
       " <Tile #12 - IMG_20200308_170810_02_02.png>,\n",
       " <Tile #13 - IMG_20200308_170810_02_03.png>,\n",
       " <Tile #14 - IMG_20200308_170810_02_04.png>,\n",
       " <Tile #15 - IMG_20200308_170810_02_05.png>,\n",
       " <Tile #16 - IMG_20200308_170810_02_06.png>,\n",
       " <Tile #17 - IMG_20200308_170810_02_07.png>,\n",
       " <Tile #18 - IMG_20200308_170810_02_08.png>,\n",
       " <Tile #19 - IMG_20200308_170810_02_09.png>,\n",
       " <Tile #20 - IMG_20200308_170810_02_10.png>,\n",
       " <Tile #21 - IMG_20200308_170810_03_01.png>,\n",
       " <Tile #22 - IMG_20200308_170810_03_02.png>,\n",
       " <Tile #23 - IMG_20200308_170810_03_03.png>,\n",
       " <Tile #24 - IMG_20200308_170810_03_04.png>,\n",
       " <Tile #25 - IMG_20200308_170810_03_05.png>,\n",
       " <Tile #26 - IMG_20200308_170810_03_06.png>,\n",
       " <Tile #27 - IMG_20200308_170810_03_07.png>,\n",
       " <Tile #28 - IMG_20200308_170810_03_08.png>,\n",
       " <Tile #29 - IMG_20200308_170810_03_09.png>,\n",
       " <Tile #30 - IMG_20200308_170810_03_10.png>,\n",
       " <Tile #31 - IMG_20200308_170810_04_01.png>,\n",
       " <Tile #32 - IMG_20200308_170810_04_02.png>,\n",
       " <Tile #33 - IMG_20200308_170810_04_03.png>,\n",
       " <Tile #34 - IMG_20200308_170810_04_04.png>,\n",
       " <Tile #35 - IMG_20200308_170810_04_05.png>,\n",
       " <Tile #36 - IMG_20200308_170810_04_06.png>,\n",
       " <Tile #37 - IMG_20200308_170810_04_07.png>,\n",
       " <Tile #38 - IMG_20200308_170810_04_08.png>,\n",
       " <Tile #39 - IMG_20200308_170810_04_09.png>,\n",
       " <Tile #40 - IMG_20200308_170810_04_10.png>,\n",
       " <Tile #41 - IMG_20200308_170810_05_01.png>,\n",
       " <Tile #42 - IMG_20200308_170810_05_02.png>,\n",
       " <Tile #43 - IMG_20200308_170810_05_03.png>,\n",
       " <Tile #44 - IMG_20200308_170810_05_04.png>,\n",
       " <Tile #45 - IMG_20200308_170810_05_05.png>,\n",
       " <Tile #46 - IMG_20200308_170810_05_06.png>,\n",
       " <Tile #47 - IMG_20200308_170810_05_07.png>,\n",
       " <Tile #48 - IMG_20200308_170810_05_08.png>,\n",
       " <Tile #49 - IMG_20200308_170810_05_09.png>,\n",
       " <Tile #50 - IMG_20200308_170810_05_10.png>,\n",
       " <Tile #51 - IMG_20200308_170810_06_01.png>,\n",
       " <Tile #52 - IMG_20200308_170810_06_02.png>,\n",
       " <Tile #53 - IMG_20200308_170810_06_03.png>,\n",
       " <Tile #54 - IMG_20200308_170810_06_04.png>,\n",
       " <Tile #55 - IMG_20200308_170810_06_05.png>,\n",
       " <Tile #56 - IMG_20200308_170810_06_06.png>,\n",
       " <Tile #57 - IMG_20200308_170810_06_07.png>,\n",
       " <Tile #58 - IMG_20200308_170810_06_08.png>,\n",
       " <Tile #59 - IMG_20200308_170810_06_09.png>,\n",
       " <Tile #60 - IMG_20200308_170810_06_10.png>,\n",
       " <Tile #61 - IMG_20200308_170810_07_01.png>,\n",
       " <Tile #62 - IMG_20200308_170810_07_02.png>,\n",
       " <Tile #63 - IMG_20200308_170810_07_03.png>,\n",
       " <Tile #64 - IMG_20200308_170810_07_04.png>,\n",
       " <Tile #65 - IMG_20200308_170810_07_05.png>,\n",
       " <Tile #66 - IMG_20200308_170810_07_06.png>,\n",
       " <Tile #67 - IMG_20200308_170810_07_07.png>,\n",
       " <Tile #68 - IMG_20200308_170810_07_08.png>,\n",
       " <Tile #69 - IMG_20200308_170810_07_09.png>,\n",
       " <Tile #70 - IMG_20200308_170810_07_10.png>,\n",
       " <Tile #71 - IMG_20200308_170810_08_01.png>,\n",
       " <Tile #72 - IMG_20200308_170810_08_02.png>,\n",
       " <Tile #73 - IMG_20200308_170810_08_03.png>,\n",
       " <Tile #74 - IMG_20200308_170810_08_04.png>,\n",
       " <Tile #75 - IMG_20200308_170810_08_05.png>,\n",
       " <Tile #76 - IMG_20200308_170810_08_06.png>,\n",
       " <Tile #77 - IMG_20200308_170810_08_07.png>,\n",
       " <Tile #78 - IMG_20200308_170810_08_08.png>,\n",
       " <Tile #79 - IMG_20200308_170810_08_09.png>,\n",
       " <Tile #80 - IMG_20200308_170810_08_10.png>,\n",
       " <Tile #81 - IMG_20200308_170810_09_01.png>,\n",
       " <Tile #82 - IMG_20200308_170810_09_02.png>,\n",
       " <Tile #83 - IMG_20200308_170810_09_03.png>,\n",
       " <Tile #84 - IMG_20200308_170810_09_04.png>,\n",
       " <Tile #85 - IMG_20200308_170810_09_05.png>,\n",
       " <Tile #86 - IMG_20200308_170810_09_06.png>,\n",
       " <Tile #87 - IMG_20200308_170810_09_07.png>,\n",
       " <Tile #88 - IMG_20200308_170810_09_08.png>,\n",
       " <Tile #89 - IMG_20200308_170810_09_09.png>,\n",
       " <Tile #90 - IMG_20200308_170810_09_10.png>,\n",
       " <Tile #91 - IMG_20200308_170810_10_01.png>,\n",
       " <Tile #92 - IMG_20200308_170810_10_02.png>,\n",
       " <Tile #93 - IMG_20200308_170810_10_03.png>,\n",
       " <Tile #94 - IMG_20200308_170810_10_04.png>,\n",
       " <Tile #95 - IMG_20200308_170810_10_05.png>,\n",
       " <Tile #96 - IMG_20200308_170810_10_06.png>,\n",
       " <Tile #97 - IMG_20200308_170810_10_07.png>,\n",
       " <Tile #98 - IMG_20200308_170810_10_08.png>,\n",
       " <Tile #99 - IMG_20200308_170810_10_09.png>,\n",
       " <Tile #100 - IMG_20200308_170810_10_10.png>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import image_slicer\n",
    "image_slicer.slice('/project/data/raw/farfalle/IMG_20200308_170810.jpg', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/project/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/project/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K     |████████████████████████████████| 378kB 1.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
      "\u001b[K     |████████████████████████████████| 276kB 47.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.13.0)\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=45919 sha256=e7bd478877faadcb5bbaebd65d0e86aa42a16da7a891011951e427c244ca9bd3\n",
      "  Stored in directory: /project/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml, keras\n",
      "Successfully installed keras-2.3.1 pyyaml-5.3.1\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penne_165622_slice_01_04.png  penne_170010_slice_02_02.png\r\n",
      "penne_165622_slice_01_05.png  penne_170010_slice_02_03.png\r\n",
      "penne_165622_slice_01_06.png  penne_170010_slice_02_04.png\r\n",
      "penne_165622_slice_01_07.png  penne_170010_slice_02_05.png\r\n",
      "penne_165622_slice_02_03.png  penne_170010_slice_02_06.png\r\n",
      "penne_165622_slice_02_04.png  penne_170010_slice_02_07.png\r\n",
      "penne_165622_slice_02_05.png  penne_170010_slice_02_08.png\r\n",
      "penne_165622_slice_03_03.png  penne_170010_slice_02_09.png\r\n",
      "penne_165622_slice_03_04.png  penne_170010_slice_03_02.png\r\n",
      "penne_165622_slice_03_05.png  penne_170010_slice_03_03.png\r\n",
      "penne_165622_slice_03_06.png  penne_170010_slice_03_04.png\r\n",
      "penne_165622_slice_03_07.png  penne_170010_slice_03_05.png\r\n",
      "penne_165622_slice_04_03.png  penne_170010_slice_03_06.png\r\n",
      "penne_165622_slice_04_04.png  penne_170010_slice_03_07.png\r\n",
      "penne_165622_slice_04_05.png  penne_170010_slice_03_08.png\r\n",
      "penne_165622_slice_04_06.png  penne_170010_slice_03_09.png\r\n",
      "penne_165622_slice_04_07.png  penne_170010_slice_04_04.png\r\n",
      "penne_165622_slice_05_03.png  penne_170010_slice_04_05.png\r\n",
      "penne_165622_slice_05_04.png  penne_170010_slice_05_02.png\r\n",
      "penne_165622_slice_05_05.png  penne_170010_slice_05_03.png\r\n",
      "penne_165622_slice_05_06.png  penne_170010_slice_05_04.png\r\n",
      "penne_165622_slice_05_07.png  penne_170010_slice_05_05.png\r\n",
      "penne_165622_slice_06_03.png  penne_170010_slice_05_06.png\r\n",
      "penne_165622_slice_06_04.png  penne_170010_slice_05_07.png\r\n",
      "penne_165622_slice_06_05.png  penne_170010_slice_05_08.png\r\n",
      "penne_165622_slice_06_06.png  penne_170010_slice_05_09.png\r\n",
      "penne_165622_slice_06_07.png  penne_170010_slice_05_10.png\r\n",
      "penne_165622_slice_07_03.png  penne_170010_slice_06_02.png\r\n",
      "penne_165622_slice_07_04.png  penne_170010_slice_06_03.png\r\n",
      "penne_165622_slice_07_05.png  penne_170010_slice_06_04.png\r\n",
      "penne_165622_slice_07_06.png  penne_170010_slice_06_05.png\r\n",
      "penne_165622_slice_07_07.png  penne_170010_slice_06_07.png\r\n",
      "penne_165622_slice_08_04.png  penne_170010_slice_07_02.png\r\n",
      "penne_165622_slice_08_05.png  penne_170010_slice_07_03.png\r\n",
      "penne_165622_slice_08_06.png  penne_170010_slice_07_05.png\r\n",
      "penne_165622_slice_09_03.png  penne_170010_slice_07_06.png\r\n",
      "penne_165622_slice_09_04.png  penne_170010_slice_07_07.png\r\n",
      "penne_165622_slice_09_05.png  penne_170010_slice_07_08.png\r\n",
      "penne_165622_slice_09_06.png  penne_170010_slice_07_09.png\r\n",
      "penne_165622_slice_09_07.png  penne_170010_slice_08_03.png\r\n",
      "penne_165629_slice_02_02.png  penne_170010_slice_08_04.png\r\n",
      "penne_165629_slice_02_04.png  penne_170010_slice_08_05.png\r\n",
      "penne_165629_slice_02_05.png  penne_170010_slice_08_06.png\r\n",
      "penne_165629_slice_02_06.png  penne_170010_slice_08_07.png\r\n",
      "penne_165629_slice_02_07.png  penne_170010_slice_08_08.png\r\n",
      "penne_165629_slice_02_08.png  penne_170010_slice_08_09.png\r\n",
      "penne_165629_slice_02_09.png  penne_170010_slice_09_02.png\r\n",
      "penne_165629_slice_03_02.png  penne_170010_slice_09_03.png\r\n",
      "penne_165629_slice_03_03.png  penne_170010_slice_09_05.png\r\n",
      "penne_165629_slice_03_04.png  penne_170010_slice_09_06.png\r\n",
      "penne_165629_slice_03_05.png  penne_170010_slice_09_07.png\r\n",
      "penne_165629_slice_03_06.png  penne_170010_slice_09_08.png\r\n",
      "penne_165629_slice_03_07.png  penne_170010_slice_09_09.png\r\n",
      "penne_165629_slice_03_08.png  penne_170015_slice_02_03.png\r\n",
      "penne_165629_slice_03_09.png  penne_170015_slice_02_04.png\r\n",
      "penne_165629_slice_04_02.png  penne_170015_slice_02_05.png\r\n",
      "penne_165629_slice_04_03.png  penne_170015_slice_02_06.png\r\n",
      "penne_165629_slice_04_04.png  penne_170015_slice_02_07.png\r\n",
      "penne_165629_slice_04_05.png  penne_170015_slice_02_08.png\r\n",
      "penne_165629_slice_04_06.png  penne_170015_slice_02_09.png\r\n",
      "penne_165629_slice_04_07.png  penne_170015_slice_03_06.png\r\n",
      "penne_165629_slice_04_08.png  penne_170015_slice_03_07.png\r\n",
      "penne_165629_slice_04_09.png  penne_170015_slice_03_08.png\r\n",
      "penne_165629_slice_05_02.png  penne_170015_slice_03_09.png\r\n",
      "penne_165629_slice_05_03.png  penne_170015_slice_04_04.png\r\n",
      "penne_165629_slice_05_04.png  penne_170015_slice_04_05.png\r\n",
      "penne_165629_slice_05_05.png  penne_170015_slice_04_06.png\r\n",
      "penne_165629_slice_05_06.png  penne_170015_slice_04_07.png\r\n",
      "penne_165629_slice_05_08.png  penne_170015_slice_04_08.png\r\n",
      "penne_165629_slice_05_09.png  penne_170015_slice_04_09.png\r\n",
      "penne_165629_slice_06_02.png  penne_170015_slice_05_02.png\r\n",
      "penne_165629_slice_06_03.png  penne_170015_slice_05_03.png\r\n",
      "penne_165629_slice_06_04.png  penne_170015_slice_05_04.png\r\n",
      "penne_165629_slice_06_05.png  penne_170015_slice_05_05.png\r\n",
      "penne_165629_slice_06_06.png  penne_170015_slice_05_06.png\r\n",
      "penne_165629_slice_06_07.png  penne_170015_slice_05_07.png\r\n",
      "penne_165629_slice_06_08.png  penne_170015_slice_05_08.png\r\n",
      "penne_165629_slice_06_09.png  penne_170015_slice_05_09.png\r\n",
      "penne_165629_slice_06_10.png  penne_170015_slice_06_03.png\r\n",
      "penne_165629_slice_07_01.png  penne_170015_slice_06_04.png\r\n",
      "penne_165629_slice_07_02.png  penne_170015_slice_06_05.png\r\n",
      "penne_165629_slice_07_03.png  penne_170015_slice_07_02.png\r\n",
      "penne_165629_slice_07_04.png  penne_170015_slice_07_03.png\r\n",
      "penne_165629_slice_07_05.png  penne_170015_slice_07_04.png\r\n",
      "penne_165629_slice_07_07.png  penne_170015_slice_07_05.png\r\n",
      "penne_165629_slice_07_08.png  penne_170015_slice_07_06.png\r\n",
      "penne_165629_slice_07_09.png  penne_170015_slice_07_07.png\r\n",
      "penne_165629_slice_07_10.png  penne_170015_slice_07_08.png\r\n",
      "penne_165629_slice_08_02.png  penne_170015_slice_07_09.png\r\n",
      "penne_165629_slice_08_03.png  penne_170015_slice_08_02.png\r\n",
      "penne_165629_slice_08_04.png  penne_170015_slice_08_03.png\r\n",
      "penne_165629_slice_08_05.png  penne_170015_slice_08_04.png\r\n",
      "penne_165629_slice_08_06.png  penne_170015_slice_08_05.png\r\n",
      "penne_165629_slice_08_07.png  penne_170015_slice_08_06.png\r\n",
      "penne_165629_slice_08_08.png  penne_170015_slice_08_08.png\r\n",
      "penne_165629_slice_09_02.png  penne_170015_slice_08_09.png\r\n",
      "penne_165629_slice_09_03.png  penne_170015_slice_09_02.png\r\n",
      "penne_165629_slice_09_04.png  penne_170015_slice_09_03.png\r\n",
      "penne_165629_slice_09_05.png  penne_170015_slice_09_05.png\r\n",
      "penne_165629_slice_09_06.png  penne_170015_slice_09_06.png\r\n",
      "penne_165629_slice_09_07.png  penne_170015_slice_09_07.png\r\n",
      "penne_165629_slice_09_08.png  penne_170015_slice_09_08.png\r\n",
      "penne_165629_slice_09_09.png  penne_170015_slice_09_09.png\r\n",
      "penne_165629_slice_09_10.png  penne_170018_slice_01_02.png\r\n",
      "penne_165631_slice_02_02.png  penne_170018_slice_01_03.png\r\n",
      "penne_165631_slice_02_04.png  penne_170018_slice_01_04.png\r\n",
      "penne_165631_slice_02_05.png  penne_170018_slice_01_05.png\r\n",
      "penne_165631_slice_02_06.png  penne_170018_slice_01_07.png\r\n",
      "penne_165631_slice_02_07.png  penne_170018_slice_02_02.png\r\n",
      "penne_165631_slice_02_08.png  penne_170018_slice_02_03.png\r\n",
      "penne_165631_slice_03_02.png  penne_170018_slice_02_04.png\r\n",
      "penne_165631_slice_03_04.png  penne_170018_slice_02_05.png\r\n",
      "penne_165631_slice_03_05.png  penne_170018_slice_02_06.png\r\n",
      "penne_165631_slice_03_06.png  penne_170018_slice_02_07.png\r\n",
      "penne_165631_slice_03_07.png  penne_170018_slice_02_08.png\r\n",
      "penne_165631_slice_03_08.png  penne_170018_slice_02_09.png\r\n",
      "penne_165631_slice_03_09.png  penne_170018_slice_03_02.png\r\n",
      "penne_165631_slice_04_02.png  penne_170018_slice_03_03.png\r\n",
      "penne_165631_slice_04_03.png  penne_170018_slice_03_04.png\r\n",
      "penne_165631_slice_04_04.png  penne_170018_slice_03_05.png\r\n",
      "penne_165631_slice_04_05.png  penne_170018_slice_03_06.png\r\n",
      "penne_165631_slice_04_06.png  penne_170018_slice_03_07.png\r\n",
      "penne_165631_slice_04_07.png  penne_170018_slice_03_08.png\r\n",
      "penne_165631_slice_04_08.png  penne_170018_slice_03_09.png\r\n",
      "penne_165631_slice_04_09.png  penne_170018_slice_04_03.png\r\n",
      "penne_165631_slice_05_02.png  penne_170018_slice_05_02.png\r\n",
      "penne_165631_slice_05_03.png  penne_170018_slice_05_03.png\r\n",
      "penne_165631_slice_05_04.png  penne_170018_slice_05_04.png\r\n",
      "penne_165631_slice_05_05.png  penne_170018_slice_05_05.png\r\n",
      "penne_165631_slice_05_06.png  penne_170018_slice_05_06.png\r\n",
      "penne_165631_slice_05_07.png  penne_170018_slice_05_07.png\r\n",
      "penne_165631_slice_05_08.png  penne_170018_slice_05_08.png\r\n",
      "penne_165631_slice_05_09.png  penne_170018_slice_05_09.png\r\n",
      "penne_165631_slice_05_10.png  penne_170018_slice_06_03.png\r\n",
      "penne_165631_slice_06_02.png  penne_170018_slice_06_04.png\r\n",
      "penne_165631_slice_06_03.png  penne_170018_slice_06_05.png\r\n",
      "penne_165631_slice_06_04.png  penne_170018_slice_06_06.png\r\n",
      "penne_165631_slice_06_05.png  penne_170018_slice_07_02.png\r\n",
      "penne_165631_slice_06_06.png  penne_170018_slice_07_04.png\r\n",
      "penne_165631_slice_06_07.png  penne_170018_slice_07_05.png\r\n",
      "penne_165631_slice_06_08.png  penne_170018_slice_07_06.png\r\n",
      "penne_165631_slice_06_09.png  penne_170018_slice_07_07.png\r\n",
      "penne_165631_slice_06_10.png  penne_170018_slice_07_08.png\r\n",
      "penne_165631_slice_07_02.png  penne_170018_slice_07_09.png\r\n",
      "penne_165631_slice_07_03.png  penne_170018_slice_08_02.png\r\n",
      "penne_165631_slice_07_04.png  penne_170018_slice_08_03.png\r\n",
      "penne_165631_slice_07_05.png  penne_170018_slice_08_04.png\r\n",
      "penne_165631_slice_07_07.png  penne_170018_slice_08_05.png\r\n",
      "penne_165631_slice_07_08.png  penne_170018_slice_08_06.png\r\n",
      "penne_165631_slice_07_09.png  penne_170018_slice_08_07.png\r\n",
      "penne_165631_slice_07_10.png  penne_170018_slice_08_08.png\r\n",
      "penne_165631_slice_08_02.png  penne_170018_slice_08_09.png\r\n",
      "penne_165631_slice_08_03.png  penne_170018_slice_09_02.png\r\n",
      "penne_165631_slice_08_04.png  penne_170018_slice_09_03.png\r\n",
      "penne_165631_slice_08_05.png  penne_170018_slice_09_05.png\r\n",
      "penne_165631_slice_08_06.png  penne_170018_slice_09_06.png\r\n",
      "penne_165631_slice_08_07.png  penne_170018_slice_09_07.png\r\n",
      "penne_165631_slice_08_08.png  penne_170018_slice_09_08.png\r\n",
      "penne_165631_slice_09_02.png  penne_170020_slice_02_02.png\r\n",
      "penne_165631_slice_09_03.png  penne_170020_slice_02_03.png\r\n",
      "penne_165631_slice_09_05.png  penne_170020_slice_02_04.png\r\n",
      "penne_165631_slice_09_06.png  penne_170020_slice_02_05.png\r\n",
      "penne_165631_slice_09_07.png  penne_170020_slice_02_06.png\r\n",
      "penne_165631_slice_09_10.png  penne_170020_slice_02_07.png\r\n",
      "penne_165631_slice_10_04.png  penne_170020_slice_02_08.png\r\n",
      "penne_165635_slice_01_05.png  penne_170020_slice_02_09.png\r\n",
      "penne_165635_slice_02_02.png  penne_170020_slice_03_05.png\r\n",
      "penne_165635_slice_02_04.png  penne_170020_slice_03_06.png\r\n",
      "penne_165635_slice_02_05.png  penne_170020_slice_03_07.png\r\n",
      "penne_165635_slice_02_06.png  penne_170020_slice_03_08.png\r\n",
      "penne_165635_slice_02_07.png  penne_170020_slice_03_09.png\r\n",
      "penne_165635_slice_02_08.png  penne_170020_slice_04_02.png\r\n",
      "penne_165635_slice_02_09.png  penne_170020_slice_04_03.png\r\n",
      "penne_165635_slice_03_02.png  penne_170020_slice_04_04.png\r\n",
      "penne_165635_slice_03_03.png  penne_170020_slice_04_05.png\r\n",
      "penne_165635_slice_03_04.png  penne_170020_slice_04_06.png\r\n",
      "penne_165635_slice_03_08.png  penne_170020_slice_04_07.png\r\n",
      "penne_165635_slice_04_02.png  penne_170020_slice_04_08.png\r\n",
      "penne_165635_slice_04_05.png  penne_170020_slice_04_09.png\r\n",
      "penne_165635_slice_04_06.png  penne_170020_slice_05_02.png\r\n",
      "penne_165635_slice_04_08.png  penne_170020_slice_05_03.png\r\n",
      "penne_165635_slice_04_09.png  penne_170020_slice_05_04.png\r\n",
      "penne_165635_slice_05_02.png  penne_170020_slice_05_05.png\r\n",
      "penne_165635_slice_05_03.png  penne_170020_slice_05_06.png\r\n",
      "penne_165635_slice_05_04.png  penne_170020_slice_05_07.png\r\n",
      "penne_165635_slice_05_06.png  penne_170020_slice_05_08.png\r\n",
      "penne_165635_slice_05_08.png  penne_170020_slice_05_09.png\r\n",
      "penne_165635_slice_05_09.png  penne_170020_slice_06_02.png\r\n",
      "penne_165635_slice_05_10.png  penne_170020_slice_06_04.png\r\n",
      "penne_165635_slice_06_02.png  penne_170020_slice_06_05.png\r\n",
      "penne_165635_slice_06_03.png  penne_170020_slice_06_06.png\r\n",
      "penne_165635_slice_06_05.png  penne_170020_slice_06_08.png\r\n",
      "penne_165635_slice_06_06.png  penne_170020_slice_06_09.png\r\n",
      "penne_165635_slice_06_07.png  penne_170020_slice_07_02.png\r\n",
      "penne_165635_slice_06_08.png  penne_170020_slice_07_03.png\r\n",
      "penne_165635_slice_06_10.png  penne_170020_slice_07_04.png\r\n",
      "penne_165635_slice_07_03.png  penne_170020_slice_07_05.png\r\n",
      "penne_165635_slice_07_04.png  penne_170020_slice_07_06.png\r\n",
      "penne_165635_slice_07_05.png  penne_170020_slice_07_07.png\r\n",
      "penne_165635_slice_07_06.png  penne_170020_slice_07_08.png\r\n",
      "penne_165635_slice_07_08.png  penne_170020_slice_07_09.png\r\n",
      "penne_165635_slice_07_09.png  penne_170020_slice_08_03.png\r\n",
      "penne_165635_slice_07_10.png  penne_170020_slice_08_05.png\r\n",
      "penne_165635_slice_08_02.png  penne_170020_slice_08_08.png\r\n",
      "penne_165635_slice_08_03.png  penne_170020_slice_08_09.png\r\n",
      "penne_165635_slice_08_04.png  penne_170020_slice_09_02.png\r\n",
      "penne_165635_slice_08_05.png  penne_170020_slice_09_03.png\r\n",
      "penne_165635_slice_08_06.png  penne_170020_slice_09_05.png\r\n",
      "penne_165635_slice_08_07.png  penne_170020_slice_09_06.png\r\n",
      "penne_165635_slice_08_08.png  penne_170020_slice_09_07.png\r\n",
      "penne_165635_slice_09_02.png  penne_170020_slice_09_08.png\r\n",
      "penne_165635_slice_09_03.png  penne_170020_slice_09_09.png\r\n",
      "penne_165635_slice_09_04.png  penne_170023_slice_02_02.png\r\n",
      "penne_165635_slice_09_05.png  penne_170023_slice_02_03.png\r\n",
      "penne_165635_slice_09_06.png  penne_170023_slice_02_04.png\r\n",
      "penne_165635_slice_09_07.png  penne_170023_slice_02_05.png\r\n",
      "penne_165656_slice_02_05.png  penne_170023_slice_02_06.png\r\n",
      "penne_165656_slice_03_03.png  penne_170023_slice_02_07.png\r\n",
      "penne_165656_slice_03_04.png  penne_170023_slice_02_08.png\r\n",
      "penne_165656_slice_03_05.png  penne_170023_slice_02_09.png\r\n",
      "penne_165656_slice_03_07.png  penne_170023_slice_03_02.png\r\n",
      "penne_165656_slice_03_08.png  penne_170023_slice_03_03.png\r\n",
      "penne_165656_slice_04_02.png  penne_170023_slice_03_04.png\r\n",
      "penne_165656_slice_04_03.png  penne_170023_slice_03_05.png\r\n",
      "penne_165656_slice_04_04.png  penne_170023_slice_03_07.png\r\n",
      "penne_165656_slice_04_05.png  penne_170023_slice_03_08.png\r\n",
      "penne_165656_slice_04_06.png  penne_170023_slice_03_09.png\r\n",
      "penne_165656_slice_04_07.png  penne_170023_slice_03_10.png\r\n",
      "penne_165656_slice_04_08.png  penne_170023_slice_04_02.png\r\n",
      "penne_165656_slice_05_02.png  penne_170023_slice_04_03.png\r\n",
      "penne_165656_slice_05_03.png  penne_170023_slice_04_04.png\r\n",
      "penne_165656_slice_05_04.png  penne_170023_slice_04_05.png\r\n",
      "penne_165656_slice_05_05.png  penne_170023_slice_04_06.png\r\n",
      "penne_165656_slice_05_06.png  penne_170023_slice_04_07.png\r\n",
      "penne_165656_slice_05_07.png  penne_170023_slice_04_08.png\r\n",
      "penne_165656_slice_05_08.png  penne_170023_slice_04_09.png\r\n",
      "penne_165656_slice_06_03.png  penne_170023_slice_05_02.png\r\n",
      "penne_165656_slice_06_05.png  penne_170023_slice_05_03.png\r\n",
      "penne_165656_slice_06_06.png  penne_170023_slice_05_04.png\r\n",
      "penne_165656_slice_06_07.png  penne_170023_slice_05_05.png\r\n",
      "penne_165656_slice_06_08.png  penne_170023_slice_05_06.png\r\n",
      "penne_165656_slice_07_02.png  penne_170023_slice_05_07.png\r\n",
      "penne_165656_slice_07_03.png  penne_170023_slice_05_08.png\r\n",
      "penne_165656_slice_07_04.png  penne_170023_slice_05_09.png\r\n",
      "penne_165656_slice_07_05.png  penne_170023_slice_05_10.png\r\n",
      "penne_165656_slice_07_06.png  penne_170023_slice_06_02.png\r\n",
      "penne_165656_slice_07_07.png  penne_170023_slice_06_06.png\r\n",
      "penne_165656_slice_07_08.png  penne_170023_slice_06_08.png\r\n",
      "penne_165656_slice_08_04.png  penne_170023_slice_06_09.png\r\n",
      "penne_165656_slice_09_01.png  penne_170023_slice_06_10.png\r\n",
      "penne_165656_slice_10_01.png  penne_170023_slice_07_02.png\r\n",
      "penne_165701_slice_03_02.png  penne_170023_slice_07_03.png\r\n",
      "penne_165701_slice_03_04.png  penne_170023_slice_07_05.png\r\n",
      "penne_165701_slice_03_05.png  penne_170023_slice_07_06.png\r\n",
      "penne_165701_slice_03_06.png  penne_170023_slice_07_07.png\r\n",
      "penne_165701_slice_03_07.png  penne_170023_slice_07_08.png\r\n",
      "penne_165701_slice_03_08.png  penne_170023_slice_07_09.png\r\n",
      "penne_165701_slice_04_02.png  penne_170023_slice_08_02.png\r\n",
      "penne_165701_slice_04_03.png  penne_170023_slice_08_03.png\r\n",
      "penne_165701_slice_04_04.png  penne_170023_slice_08_04.png\r\n",
      "penne_165701_slice_04_05.png  penne_170023_slice_08_05.png\r\n",
      "penne_165701_slice_04_06.png  penne_170023_slice_09_02.png\r\n",
      "penne_165701_slice_04_07.png  penne_170023_slice_09_03.png\r\n",
      "penne_165701_slice_04_08.png  penne_170023_slice_09_04.png\r\n",
      "penne_165701_slice_05_02.png  penne_170023_slice_09_05.png\r\n",
      "penne_165701_slice_05_03.png  penne_170023_slice_09_06.png\r\n",
      "penne_165701_slice_05_04.png  penne_170023_slice_09_07.png\r\n",
      "penne_165701_slice_05_05.png  penne_170023_slice_09_08.png\r\n",
      "penne_165701_slice_05_06.png  penne_170023_slice_09_09.png\r\n",
      "penne_165701_slice_05_07.png  penne_170030_slice_01_02.png\r\n",
      "penne_165701_slice_05_08.png  penne_170030_slice_01_03.png\r\n",
      "penne_165701_slice_06_02.png  penne_170030_slice_01_04.png\r\n",
      "penne_165701_slice_06_03.png  penne_170030_slice_01_05.png\r\n",
      "penne_165701_slice_06_04.png  penne_170030_slice_02_02.png\r\n",
      "penne_165701_slice_06_05.png  penne_170030_slice_02_03.png\r\n",
      "penne_165701_slice_06_06.png  penne_170030_slice_02_04.png\r\n",
      "penne_165701_slice_06_07.png  penne_170030_slice_02_05.png\r\n",
      "penne_165701_slice_06_08.png  penne_170030_slice_02_06.png\r\n",
      "penne_165701_slice_07_02.png  penne_170030_slice_02_07.png\r\n",
      "penne_165701_slice_07_03.png  penne_170030_slice_02_08.png\r\n",
      "penne_165701_slice_07_04.png  penne_170030_slice_02_09.png\r\n",
      "penne_165701_slice_07_05.png  penne_170030_slice_03_02.png\r\n",
      "penne_165701_slice_07_06.png  penne_170030_slice_03_03.png\r\n",
      "penne_165701_slice_07_08.png  penne_170030_slice_03_04.png\r\n",
      "penne_165701_slice_08_02.png  penne_170030_slice_03_05.png\r\n",
      "penne_165701_slice_08_03.png  penne_170030_slice_03_06.png\r\n",
      "penne_165701_slice_08_04.png  penne_170030_slice_03_07.png\r\n",
      "penne_165701_slice_08_05.png  penne_170030_slice_03_08.png\r\n",
      "penne_165701_slice_08_06.png  penne_170030_slice_03_09.png\r\n",
      "penne_165701_slice_08_07.png  penne_170030_slice_04_02.png\r\n",
      "penne_165701_slice_08_08.png  penne_170030_slice_05_02.png\r\n",
      "penne_165701_slice_09_01.png  penne_170030_slice_05_03.png\r\n",
      "penne_165701_slice_10_01.png  penne_170030_slice_05_04.png\r\n",
      "penne_165705_slice_03_02.png  penne_170030_slice_05_05.png\r\n",
      "penne_165705_slice_03_03.png  penne_170030_slice_05_06.png\r\n",
      "penne_165705_slice_03_04.png  penne_170030_slice_05_07.png\r\n",
      "penne_165705_slice_03_05.png  penne_170030_slice_05_08.png\r\n",
      "penne_165705_slice_03_06.png  penne_170030_slice_05_09.png\r\n",
      "penne_165705_slice_03_07.png  penne_170030_slice_05_10.png\r\n",
      "penne_165705_slice_04_02.png  penne_170030_slice_06_04.png\r\n",
      "penne_165705_slice_04_03.png  penne_170030_slice_06_05.png\r\n",
      "penne_165705_slice_04_04.png  penne_170030_slice_07_02.png\r\n",
      "penne_165705_slice_04_05.png  penne_170030_slice_07_03.png\r\n",
      "penne_165705_slice_04_06.png  penne_170030_slice_07_04.png\r\n",
      "penne_165705_slice_04_07.png  penne_170030_slice_07_05.png\r\n",
      "penne_165705_slice_05_02.png  penne_170030_slice_07_06.png\r\n",
      "penne_165705_slice_05_03.png  penne_170030_slice_07_07.png\r\n",
      "penne_165705_slice_05_04.png  penne_170030_slice_07_08.png\r\n",
      "penne_165705_slice_05_05.png  penne_170030_slice_07_09.png\r\n",
      "penne_165705_slice_05_06.png  penne_170030_slice_08_02.png\r\n",
      "penne_165705_slice_05_07.png  penne_170030_slice_08_03.png\r\n",
      "penne_165705_slice_06_02.png  penne_170030_slice_08_04.png\r\n",
      "penne_165705_slice_06_03.png  penne_170030_slice_08_05.png\r\n",
      "penne_165705_slice_06_04.png  penne_170030_slice_08_06.png\r\n",
      "penne_165705_slice_06_05.png  penne_170030_slice_08_08.png\r\n",
      "penne_165705_slice_06_06.png  penne_170030_slice_08_09.png\r\n",
      "penne_165705_slice_06_07.png  penne_170030_slice_09_02.png\r\n",
      "penne_165705_slice_07_02.png  penne_170030_slice_09_03.png\r\n",
      "penne_165705_slice_07_03.png  penne_170030_slice_09_05.png\r\n",
      "penne_165705_slice_07_04.png  penne_170030_slice_09_06.png\r\n",
      "penne_165705_slice_07_05.png  penne_170030_slice_09_07.png\r\n",
      "penne_165705_slice_07_06.png  penne_170030_slice_09_08.png\r\n",
      "penne_165705_slice_07_07.png  penne_170030_slice_09_09.png\r\n",
      "penne_165705_slice_08_02.png  penne_170033_slice_02_02.png\r\n",
      "penne_165705_slice_08_03.png  penne_170033_slice_02_03.png\r\n",
      "penne_165705_slice_08_04.png  penne_170033_slice_02_04.png\r\n",
      "penne_165705_slice_08_05.png  penne_170033_slice_02_05.png\r\n",
      "penne_165705_slice_08_06.png  penne_170033_slice_02_06.png\r\n",
      "penne_165705_slice_08_07.png  penne_170033_slice_02_07.png\r\n",
      "penne_165708_slice_03_02.png  penne_170033_slice_02_08.png\r\n",
      "penne_165708_slice_03_04.png  penne_170033_slice_02_09.png\r\n",
      "penne_165708_slice_03_05.png  penne_170033_slice_03_06.png\r\n",
      "penne_165708_slice_03_06.png  penne_170033_slice_03_07.png\r\n",
      "penne_165708_slice_03_07.png  penne_170033_slice_03_08.png\r\n",
      "penne_165708_slice_03_08.png  penne_170033_slice_03_09.png\r\n",
      "penne_165708_slice_04_02.png  penne_170033_slice_04_02.png\r\n",
      "penne_165708_slice_04_03.png  penne_170033_slice_04_03.png\r\n",
      "penne_165708_slice_04_04.png  penne_170033_slice_04_04.png\r\n",
      "penne_165708_slice_04_05.png  penne_170033_slice_04_05.png\r\n",
      "penne_165708_slice_04_06.png  penne_170033_slice_04_06.png\r\n",
      "penne_165708_slice_04_07.png  penne_170033_slice_04_07.png\r\n",
      "penne_165708_slice_04_08.png  penne_170033_slice_04_08.png\r\n",
      "penne_165708_slice_05_02.png  penne_170033_slice_04_09.png\r\n",
      "penne_165708_slice_05_03.png  penne_170033_slice_05_03.png\r\n",
      "penne_165708_slice_05_04.png  penne_170033_slice_05_04.png\r\n",
      "penne_165708_slice_05_05.png  penne_170033_slice_05_05.png\r\n",
      "penne_165708_slice_05_06.png  penne_170033_slice_05_06.png\r\n",
      "penne_165708_slice_05_08.png  penne_170033_slice_05_07.png\r\n",
      "penne_165708_slice_06_02.png  penne_170033_slice_05_09.png\r\n",
      "penne_165708_slice_06_03.png  penne_170033_slice_05_10.png\r\n",
      "penne_165708_slice_06_04.png  penne_170033_slice_06_02.png\r\n",
      "penne_165708_slice_06_05.png  penne_170033_slice_06_03.png\r\n",
      "penne_165708_slice_06_06.png  penne_170033_slice_06_06.png\r\n",
      "penne_165708_slice_06_08.png  penne_170033_slice_06_07.png\r\n",
      "penne_165708_slice_07_02.png  penne_170033_slice_06_08.png\r\n",
      "penne_165708_slice_07_03.png  penne_170033_slice_06_09.png\r\n",
      "penne_165708_slice_07_04.png  penne_170033_slice_06_10.png\r\n",
      "penne_165708_slice_07_05.png  penne_170033_slice_07_02.png\r\n",
      "penne_165708_slice_07_06.png  penne_170033_slice_07_03.png\r\n",
      "penne_165708_slice_07_08.png  penne_170033_slice_07_04.png\r\n",
      "penne_165708_slice_08_02.png  penne_170033_slice_07_05.png\r\n",
      "penne_165708_slice_08_03.png  penne_170033_slice_07_06.png\r\n",
      "penne_165708_slice_08_04.png  penne_170033_slice_07_07.png\r\n",
      "penne_165708_slice_08_05.png  penne_170033_slice_07_09.png\r\n",
      "penne_165708_slice_08_08.png  penne_170033_slice_08_06.png\r\n",
      "penne_165708_slice_09_01.png  penne_170033_slice_08_07.png\r\n",
      "penne_170007_slice_01_02.png  penne_170033_slice_08_09.png\r\n",
      "penne_170007_slice_01_03.png  penne_170033_slice_09_02.png\r\n",
      "penne_170007_slice_01_04.png  penne_170033_slice_09_03.png\r\n",
      "penne_170007_slice_01_05.png  penne_170033_slice_09_04.png\r\n",
      "penne_170007_slice_01_06.png  penne_170033_slice_09_05.png\r\n",
      "penne_170007_slice_01_07.png  penne_170033_slice_09_06.png\r\n",
      "penne_170007_slice_01_08.png  penne_170033_slice_09_07.png\r\n",
      "penne_170007_slice_01_09.png  penne_170033_slice_09_08.png\r\n",
      "penne_170007_slice_02_04.png  penne_170033_slice_09_09.png\r\n",
      "penne_170007_slice_02_06.png  penne_170037_slice_09_02.png\r\n",
      "penne_170007_slice_02_08.png  penne_170037_slice_09_03.png\r\n",
      "penne_170007_slice_02_09.png  penne_170037_slice_09_04.png\r\n",
      "penne_170007_slice_03_02.png  penne_170037_slice_09_05.png\r\n",
      "penne_170007_slice_03_03.png  penne_170037_slice_09_06.png\r\n",
      "penne_170007_slice_03_04.png  penne_170037_slice_09_07.png\r\n",
      "penne_170007_slice_03_05.png  penne_170037_slice_09_08.png\r\n",
      "penne_170007_slice_03_06.png  penne_170037_slice_09_09.png\r\n",
      "penne_170007_slice_03_07.png  penne_170053_slice_02_02.png\r\n",
      "penne_170007_slice_03_08.png  penne_170053_slice_02_03.png\r\n",
      "penne_170007_slice_03_09.png  penne_170053_slice_02_04.png\r\n",
      "penne_170007_slice_04_04.png  penne_170053_slice_02_05.png\r\n",
      "penne_170007_slice_04_05.png  penne_170053_slice_02_06.png\r\n",
      "penne_170007_slice_04_06.png  penne_170053_slice_02_07.png\r\n",
      "penne_170007_slice_04_07.png  penne_170053_slice_02_08.png\r\n",
      "penne_170007_slice_05_02.png  penne_170053_slice_02_09.png\r\n",
      "penne_170007_slice_05_03.png  penne_170053_slice_03_02.png\r\n",
      "penne_170007_slice_05_04.png  penne_170053_slice_03_03.png\r\n",
      "penne_170007_slice_05_05.png  penne_170053_slice_03_04.png\r\n",
      "penne_170007_slice_05_06.png  penne_170053_slice_03_05.png\r\n",
      "penne_170007_slice_05_07.png  penne_170053_slice_03_06.png\r\n",
      "penne_170007_slice_05_08.png  penne_170053_slice_03_07.png\r\n",
      "penne_170007_slice_05_09.png  penne_170053_slice_03_08.png\r\n",
      "penne_170007_slice_05_10.png  penne_170053_slice_03_09.png\r\n",
      "penne_170007_slice_06_02.png  penne_170053_slice_04_02.png\r\n",
      "penne_170007_slice_06_03.png  penne_170053_slice_04_04.png\r\n",
      "penne_170007_slice_06_04.png  penne_170053_slice_04_05.png\r\n",
      "penne_170007_slice_06_05.png  penne_170053_slice_04_06.png\r\n",
      "penne_170007_slice_06_06.png  penne_170053_slice_04_07.png\r\n",
      "penne_170007_slice_06_07.png  penne_170053_slice_04_08.png\r\n",
      "penne_170007_slice_06_09.png  penne_170053_slice_04_09.png\r\n",
      "penne_170007_slice_07_06.png  penne_170053_slice_05_02.png\r\n",
      "penne_170007_slice_07_07.png  penne_170053_slice_05_03.png\r\n",
      "penne_170007_slice_07_08.png  penne_170053_slice_05_04.png\r\n",
      "penne_170007_slice_07_09.png  penne_170053_slice_05_05.png\r\n",
      "penne_170007_slice_08_02.png  penne_170053_slice_05_06.png\r\n",
      "penne_170007_slice_08_03.png  penne_170053_slice_05_07.png\r\n",
      "penne_170007_slice_08_04.png  penne_170053_slice_05_08.png\r\n",
      "penne_170007_slice_08_05.png  penne_170053_slice_05_09.png\r\n",
      "penne_170007_slice_08_06.png  penne_170053_slice_06_02.png\r\n",
      "penne_170007_slice_08_07.png  penne_170053_slice_06_03.png\r\n",
      "penne_170007_slice_08_08.png  penne_170053_slice_06_04.png\r\n",
      "penne_170007_slice_08_09.png  penne_170053_slice_06_05.png\r\n",
      "penne_170009_slice_01_02.png  penne_170053_slice_07_02.png\r\n",
      "penne_170009_slice_01_03.png  penne_170053_slice_07_05.png\r\n",
      "penne_170009_slice_01_04.png  penne_170053_slice_07_06.png\r\n",
      "penne_170009_slice_01_05.png  penne_170053_slice_07_07.png\r\n",
      "penne_170009_slice_01_06.png  penne_170053_slice_07_08.png\r\n",
      "penne_170009_slice_02_02.png  penne_170053_slice_07_09.png\r\n",
      "penne_170009_slice_02_03.png  penne_170053_slice_08_02.png\r\n",
      "penne_170009_slice_02_04.png  penne_170053_slice_08_03.png\r\n",
      "penne_170009_slice_02_05.png  penne_170053_slice_08_04.png\r\n",
      "penne_170009_slice_02_06.png  penne_170053_slice_08_05.png\r\n",
      "penne_170009_slice_02_07.png  penne_170053_slice_08_06.png\r\n",
      "penne_170009_slice_02_08.png  penne_170053_slice_08_07.png\r\n",
      "penne_170009_slice_02_09.png  penne_170053_slice_08_08.png\r\n",
      "penne_170009_slice_03_02.png  penne_170053_slice_08_09.png\r\n",
      "penne_170009_slice_03_03.png  penne_170053_slice_09_05.png\r\n",
      "penne_170009_slice_03_04.png  penne_170053_slice_09_06.png\r\n",
      "penne_170009_slice_03_05.png  penne_170053_slice_09_07.png\r\n",
      "penne_170009_slice_03_06.png  penne_170053_slice_09_08.png\r\n",
      "penne_170009_slice_03_07.png  penne_170053_slice_09_09.png\r\n",
      "penne_170009_slice_03_08.png  penne_170055_slice_01_02.png\r\n",
      "penne_170009_slice_03_09.png  penne_170055_slice_01_03.png\r\n",
      "penne_170009_slice_04_02.png  penne_170055_slice_01_04.png\r\n",
      "penne_170009_slice_04_03.png  penne_170055_slice_02_02.png\r\n",
      "penne_170009_slice_04_04.png  penne_170055_slice_02_03.png\r\n",
      "penne_170009_slice_04_05.png  penne_170055_slice_02_04.png\r\n",
      "penne_170009_slice_04_06.png  penne_170055_slice_02_05.png\r\n",
      "penne_170009_slice_04_07.png  penne_170055_slice_02_06.png\r\n",
      "penne_170009_slice_04_08.png  penne_170055_slice_02_07.png\r\n",
      "penne_170009_slice_04_09.png  penne_170055_slice_02_08.png\r\n",
      "penne_170009_slice_05_02.png  penne_170055_slice_02_09.png\r\n",
      "penne_170009_slice_05_03.png  penne_170055_slice_03_02.png\r\n",
      "penne_170009_slice_05_04.png  penne_170055_slice_03_03.png\r\n",
      "penne_170009_slice_05_05.png  penne_170055_slice_03_04.png\r\n",
      "penne_170009_slice_05_06.png  penne_170055_slice_03_05.png\r\n",
      "penne_170009_slice_05_07.png  penne_170055_slice_03_06.png\r\n",
      "penne_170009_slice_05_08.png  penne_170055_slice_03_07.png\r\n",
      "penne_170009_slice_05_09.png  penne_170055_slice_03_08.png\r\n",
      "penne_170009_slice_06_02.png  penne_170055_slice_03_09.png\r\n",
      "penne_170009_slice_06_03.png  penne_170055_slice_05_02.png\r\n",
      "penne_170009_slice_06_04.png  penne_170055_slice_05_03.png\r\n",
      "penne_170009_slice_06_05.png  penne_170055_slice_05_04.png\r\n",
      "penne_170009_slice_07_02.png  penne_170055_slice_05_05.png\r\n",
      "penne_170009_slice_07_03.png  penne_170055_slice_05_06.png\r\n",
      "penne_170009_slice_07_04.png  penne_170055_slice_05_07.png\r\n",
      "penne_170009_slice_07_05.png  penne_170055_slice_05_08.png\r\n",
      "penne_170009_slice_07_06.png  penne_170055_slice_05_09.png\r\n",
      "penne_170009_slice_07_07.png  penne_170055_slice_06_02.png\r\n",
      "penne_170009_slice_07_08.png  penne_170055_slice_06_03.png\r\n",
      "penne_170009_slice_07_09.png  penne_170055_slice_06_04.png\r\n",
      "penne_170009_slice_08_02.png  penne_170055_slice_06_05.png\r\n",
      "penne_170009_slice_08_03.png  penne_170055_slice_06_06.png\r\n",
      "penne_170009_slice_08_04.png  penne_170055_slice_07_05.png\r\n",
      "penne_170009_slice_08_05.png  penne_170055_slice_07_06.png\r\n",
      "penne_170009_slice_08_06.png  penne_170055_slice_07_07.png\r\n",
      "penne_170009_slice_08_07.png  penne_170055_slice_07_08.png\r\n",
      "penne_170009_slice_08_08.png  penne_170055_slice_07_09.png\r\n",
      "penne_170009_slice_08_09.png  penne_170055_slice_08_02.png\r\n",
      "penne_170009_slice_09_02.png  penne_170055_slice_08_03.png\r\n",
      "penne_170009_slice_09_03.png  penne_170055_slice_08_04.png\r\n",
      "penne_170009_slice_09_05.png  penne_170055_slice_08_05.png\r\n",
      "penne_170009_slice_09_06.png  penne_170055_slice_08_06.png\r\n",
      "penne_170009_slice_09_07.png  penne_170055_slice_08_07.png\r\n",
      "penne_170009_slice_09_08.png  penne_170055_slice_08_08.png\r\n",
      "penne_170009_slice_09_09.png  penne_170055_slice_08_09.png\r\n",
      "penne_170010_slice_01_02.png  penne_170055_slice_09_05.png\r\n",
      "penne_170010_slice_01_03.png  penne_170055_slice_09_06.png\r\n",
      "penne_170010_slice_01_04.png  penne_170055_slice_09_07.png\r\n",
      "penne_170010_slice_01_05.png  penne_170055_slice_09_08.png\r\n",
      "penne_170010_slice_01_06.png\r\n"
     ]
    }
   ],
   "source": [
    "!ls /project/data/selected_images/penne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageDataGenerator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img(f'/project/data/selected_images/penne/penne_165622_slice_02_04.png')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='/project/data/preview', save_prefix='penne', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(302, 403, 3)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_to_array(img).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need to split our data into Train/ Validation and Test Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "### Simple Binary Classification - orzo vs bowtie\n",
    "* Set up a folder for binary_classification datasets\n",
    "* copy the `selected` images\n",
    "* We will randomly assign to `test` and `train` datasets\n",
    "* add `/test` and `/train` sub-folders\n",
    "* Run with simple conv net bellow: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "\n",
    "# Catigorical\n",
    "* Add 3rd category - will need to label `-[1,0,0],[0,1,0],[0,0,1]`\n",
    "* Not sure how to save the target value..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/project/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/project/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting wandb\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/6f/f8485396e1e17c6b4257eecbcae1869d4d27ec960eb2bc06ea3fb829bc9a/wandb-0.8.30-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 1.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.13.0)\n",
      "Collecting psutil>=5.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/b8/3512f0e93e0db23a71d82485ba256071ebef99b227351f0f5540f744af41/psutil-5.7.0.tar.gz (449kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 71.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-ml-py3>=7.352.0\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/64/cce82bddb80c0b0f5c703bbdafa94bfb69a1c5ad7a79cff00b482468f0d3/nvidia-ml-py3-7.352.0.tar.gz\n",
      "Collecting gql==0.2.0\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/6f/cf9a3056045518f06184e804bae89390eb706168349daa9dff8ac609962a/gql-0.2.0.tar.gz\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
      "Collecting sentry-sdk>=0.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/7e/19545324e83db4522b885808cd913c3b93ecc0c88b03e037b78c6a417fa8/sentry_sdk-0.14.3-py2.py3-none-any.whl (103kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 73.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting subprocess32>=3.5.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 46.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting Click>=7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/c0/4d8f43a9b16e289f36478422031b8a63b54b6ac3b1ba605d602f10dd54d6/click-7.1.1-py2.py3-none-any.whl (82kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 56.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.3.1)\n",
      "Collecting configparser>=3.8.1\n",
      "  Downloading https://files.pythonhosted.org/packages/7a/2a/95ed0501cf5d8709490b1d3a3f9b5cf340da6c433f896bbe9ce08dbe6785/configparser-4.0.2-py2.py3-none-any.whl\n",
      "Collecting watchdog>=0.8.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/c3/ed6d992006837e011baca89476a4bbffb0a91602432f73bd4473816c76e2/watchdog-0.10.2.tar.gz (95kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 16.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting GitPython>=1.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/2f/6a366d56c9b1355b0880be9ea66b166cb3536392638d8d91413ec66305ad/GitPython-3.1.0-py3-none-any.whl (450kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 39.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.0.0->wandb) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (1.25.7)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
      "Collecting graphql-core<2,>=0.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/89/00ad5e07524d8c523b14d70c685e0299a8b0de6d0727e368c41b89b7ed0b/graphql-core-1.1.tar.gz (70kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 34.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting promise<3,>=2.0\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/9c/fb5d48abfe5d791cd496e4242ebcf87a4bb2e0c3dcd6e0ae68c11426a528/promise-2.3.tar.gz\n",
      "Collecting pathtools>=0.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/f5/8f84b3bf9d94bdf2454a302f2fa375832b53660ea532586b8a55ff16ae9a/gitdb-4.0.2-py3-none-any.whl (63kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 76.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting smmap<4,>=3.0.1\n",
      "  Downloading https://files.pythonhosted.org/packages/35/d2/27777ab463cd44842c78305fa8097dfba0d94768abbb7e1c4d88f1fa1a0b/smmap-3.0.1-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: psutil, nvidia-ml-py3, gql, subprocess32, watchdog, graphql-core, promise, pathtools\n",
      "  Building wheel for psutil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for psutil: filename=psutil-5.7.0-cp36-cp36m-linux_x86_64.whl size=279869 sha256=3c3b3f301a830b04b90a0f7f3ed4890888721295da2cbf8872d66ef788c1582f\n",
      "  Stored in directory: /project/.cache/pip/wheels/d7/69/b4/3200b95828d1f0ddb3cb5699083717f4fdbd9b4223d0644c57\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-cp36-none-any.whl size=20124 sha256=37cc5459c8c76ae3577f2f494e81dc2786367370e752430207367821b44a6158\n",
      "  Stored in directory: /project/.cache/pip/wheels/e4/1d/06/640c93f5270d67d0247f30be91f232700d19023f9e66d735c7\n",
      "  Building wheel for gql (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gql: filename=gql-0.2.0-cp36-none-any.whl size=8312 sha256=c2e52d1ec4b23a67255c29e9e0a260ad01b75651faa598f366851eda906f38a3\n",
      "  Stored in directory: /project/.cache/pip/wheels/ce/0e/7b/58a8a5268655b3ad74feef5aa97946f0addafb3cbb6bd2da23\n",
      "  Building wheel for subprocess32 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=3301 sha256=fae21cdafe8a39478b87cce715cc5e007e650eeac60c72397393476776633810\n",
      "  Stored in directory: /project/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
      "  Building wheel for watchdog (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for watchdog: filename=watchdog-0.10.2-cp36-none-any.whl size=74802 sha256=cf3d93b29dc74dee0001fd3f7f12598de37fa271173f77a955a1e4af604a4295\n",
      "  Stored in directory: /project/.cache/pip/wheels/bc/ed/6c/028dea90d31b359cd2a7c8b0da4db80e41d24a59614154072e\n",
      "  Building wheel for graphql-core (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for graphql-core: filename=graphql_core-1.1-cp36-none-any.whl size=105790 sha256=92f3a0c6f74fc27c55380fed6040e4fc89eb5825979a5a46e692f432dd6a1ee7\n",
      "  Stored in directory: /project/.cache/pip/wheels/45/99/d7/c424029bb0fe910c63b68dbf2aa20d3283d023042521bcd7d5\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-cp36-none-any.whl size=23950 sha256=b4b6ce9003b63457f54cae8bc63c3eb87222eb5862110f5fb68f060a3a7d05bb\n",
      "  Stored in directory: /project/.cache/pip/wheels/19/49/34/c3c1e78bcb954c49e5ec0d31784fe63d14d427f316b12fbde9\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8605 sha256=a6ec88b59bdfe2c2eebf08ac2c7fc602b52600bce60ac8414641ff2172bc3f6b\n",
      "  Stored in directory: /project/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
      "Successfully built psutil nvidia-ml-py3 gql subprocess32 watchdog graphql-core promise pathtools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: psutil, nvidia-ml-py3, promise, graphql-core, gql, docker-pycreds, shortuuid, sentry-sdk, subprocess32, Click, configparser, pathtools, watchdog, smmap, gitdb, GitPython, wandb\n",
      "Successfully installed Click-7.1.1 GitPython-3.1.0 configparser-4.0.2 docker-pycreds-0.4.0 gitdb-4.0.2 gql-0.2.0 graphql-core-1.1 nvidia-ml-py3-7.352.0 pathtools-0.1.2 promise-2.3 psutil-5.7.0 sentry-sdk-0.14.3 shortuuid-1.0.1 smmap-3.0.1 subprocess32-3.5.4 wandb-0.8.30 watchdog-0.10.2\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /project/.netrc\r\n",
      "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!wandb login MY_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/cattleman/pasta-tron\" target=\"_blank\">https://app.wandb.ai/cattleman/pasta-tron</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/cattleman/pasta-tron/runs/2c024jhh\" target=\"_blank\">https://app.wandb.ai/cattleman/pasta-tron/runs/2c024jhh</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/cattleman/pasta-tron/runs/2c024jhh"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init wandb\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.init(project=\"pasta-tron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defualt Values for hyper params\n",
    "config = wandb.config # Config is a var that holds and saved hyperparams and inputs\n",
    "\n",
    "config.learning_rate = 0.01\n",
    "config.batch_size = 16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow this resource: https://colab.research.google.com/drive/1pMcNYctQpRoBKD5Z0iXeFWQD8hIDgzCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplfied vgg\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Set of Conv2D, Conv2D, MaxPooling2D layers with 32 and 64 filters\n",
    "model.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = (3, 3), padding = 'same',\n",
    "                 activation ='relu', input_shape = input_shape))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattens our array so we can feed the convolution layer outputs (a matrix) into our fully connected layer (an array)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512, activation ='relu'))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation = \"softmax\"))\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.Nadam(lr=config.learning_rate, beta_1=0.9, beta_2=0.999, clipnorm=1.0)\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_1/MaxPool' (op: 'MaxPool') with input shapes: [?,1,148,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1618\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1619\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1620\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_1/MaxPool' (op: 'MaxPool') with input shapes: [?,1,148,32].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-9dcceefdb663>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    203\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                                         data_format=self.data_format)\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36m_pooling_function\u001b[0;34m(self, inputs, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[1;32m    266\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[1;32m    267\u001b[0m                           \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                           pool_mode='max')\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[1;32m   4070\u001b[0m         x = tf.nn.max_pool(x, pool_size, strides,\n\u001b[1;32m   4071\u001b[0m                            \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4072\u001b[0;31m                            data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   4073\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4074\u001b[0m         x = tf.nn.avg_pool(x, pool_size, strides,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mmax_pool_v2\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   3824\u001b[0m       \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3825\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3826\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   3827\u001b[0m \u001b[0;31m# pylint: enable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   5198\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[1;32m   5199\u001b[0m         \u001b[0;34m\"MaxPool\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5200\u001b[0;31m                    data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   5201\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5202\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    740\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    741\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3320\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3321\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3322\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3323\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3324\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1784\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1785\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1786\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1787\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1620\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1622\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_1/MaxPool' (op: 'MaxPool') with input shapes: [?,1,148,32]."
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(3, 150, 150)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#               optimizer=keras.optimizers.Adadelta(),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `model.fit_generator` not found.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size,\n",
    "        \n",
    ")\n",
    "model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
